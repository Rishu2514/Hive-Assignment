Q-1- What is the definition of Hive? What is the present version of Hive?
A-1-Hive is a data warehousing and SQL-like query language that facilitates querying and managing large datasets residing in distributed
storage systems, such as Hadoop Distributed File System (HDFS), Amazon S3, or Microsoft Azure Data Lake Storage.Hive translates SQL-like
queries into MapReduce, Apache Spark, or Tez jobs, which are then executed on a cluster of machines in a distributed and parallelized manner.
Hive also provides data summarization, query optimization, partitioning, and indexing capabilities to improve query performance.
The current version of hive 16 November 2022: release 4.0.0-alpha-2 available.

Q-2- Is Hive suitable to be used for OLTP systems? Why?
A-2-Hive is not typically used for Online Transaction Processing (OLTP) systems, as it is primarily designed for querying and analyzing
large volumes of data in a batch-oriented manner.OLTP systems require high transactional throughput and low-latency processing for supporting
real-time, operational workloads such as recording, updating, and retrieving individual transactions. In contrast, Hive is optimized for performing
complex, long-running analytical queries that scan and aggregate large datasets.Furthermore, Hive uses a schema-on-read approach, which means that
the structure of the data is not defined until it is read during query execution. This makes it flexible for ad-hoc analysis but not suitable for
applications that require strict schema enforcement, data consistency, and ACID transactions.Therefore, Hive is better suited for Online Analytical
Processing (OLAP) workloads that involve running complex, data-intensive queries on large datasets, rather than OLTP workloads that require 
high-speed, low-latency transaction processing.

Q-3-How is HIVE different from RDBMS? Does hive support ACID
transactions. If not then give the proper reason.
A-3-Hive and traditional Relational Database Management Systems (RDBMS) differ in several ways:
Data Structure: RDBMS typically use a fixed schema that defines the structure of the data, whereas Hive uses a schema-on-read approach that allows
for flexibility in data structure.
Data Volume: RDBMS are best suited for managing smaller, highly structured data sets, whereas Hive is designed to handle large-scale, unstructured
or semi-structured data.
Data Processing: RDBMS excel at transaction processing and online transaction processing (OLTP), while Hive is optimized for batch processing and
analytics.
Regarding ACID transactions, Hive does not natively support them. ACID (Atomicity, Consistency, Isolation, and Durability) transactions are 
essential for maintaining data consistency and integrity in transactional systems, but they come with a performance cost. As Hive is designed for
batch processing and analytical workloads, it prioritizes query performance over transaction processing.However, Hive does support limited
transactions, such as insert, delete, and update operations, through its transactional tables feature, which uses a combination of locking, 
logging, and snapshot isolation to ensure data consistency. However, this feature is not intended for high-concurrency or high-transaction-rate
workloads, and it may not provide the same level of consistency guarantees as ACID transactions in RDBMS.In summary, while Hive and RDBMS share
some similarities, they are designed for different use cases, and their capabilities and limitations reflect their intended purposes. Hive is 
optimized for processing and analyzing large-scale, unstructured or semi-structured data, whereas RDBMS are designed for managing smaller, highly
structured data sets and supporting transaction processing.

Q-4-Explain the hive architecture and the different components of a Hive architecture?
A-4-Hive is an open-source data warehousing and SQL querying platform that is built on top of Apache Hadoop. It is designed to provide a simple
and efficient way to process and analyze large datasets using SQL-like queries. Hive architecture consists of three main components:
*HiveQL:HiveQL is a SQL-like language that is used to write queries against data stored in the Hadoop Distributed File System (HDFS) or other 
supported storage systems such as Apache HBase or Amazon S3. It is a declarative language, which means that users specify what they want to 
retrieve or manipulate without specifying how to do it.
*Metastore:Metastore is a repository that stores metadata about the Hive tables, such as their schema and location in HDFS. It provides a unified
view of the metadata across all Hive instances, which enables sharing of metadata between different Hive instances and tools.
*Execution Engine:The execution engine is responsible for compiling and executing the queries written in HiveQL. It consists of two main components
1.Compiler: The compiler parses the HiveQL queries and converts them into a logical execution plan, which is a set of MapReduce or Tez jobs.
2.Execution Runtime: The execution runtime executes the MapReduce or Tez jobs generated by the compiler.
In addition to these main components, there are other important components in the Hive architecture, including:
*Driver:The driver is responsible for coordinating the interaction between the user, HiveQL, the Metastore, and the Execution Engine. It accepts
the queries submitted by the user, communicates with the Metastore to retrieve metadata, and interacts with the Execution Engine to execute the
queries.
*SerDe:The SerDe (Serializer/Deserializer) is responsible for serializing the data in the Hive tables into a format that can be stored in HDFS,
and deserializing it back into its original form when the data is retrieved. There are several built-in SerDe classes, as well as the ability to
write custom SerDe classes.
*Storage Handler:The Storage Handler is responsible for managing the interaction between Hive and the underlying storage system. There are several
built-in Storage Handlers for HDFS, HBase, and other systems, as well as the ability to write custom Storage Handlers.


Q-5-Mention what Hive query processor does? And Mention what are the components of a Hive query processor?
A-5-The Hive query processor is responsible for interpreting the HiveQL queries, generating the execution plan, and executing the plan against the
data stored in the Hadoop Distributed File System (HDFS) or other supported storage systems.
The components of a Hive query processor are:
*Parser:The parser is responsible for parsing the HiveQL query and producing an abstract syntax tree (AST) that represents the logical structure 
of the query.
*Semantic Analyzer:The Semantic Analyzer checks the AST produced by the parser and performs semantic analysis to ensure that the query is well-
formed and the references to tables and columns are valid.
*Query Optimizer:The query optimizer analyzes the query and produces an optimized execution plan that reduces the amount of data that needs to be
processed and minimizes the time required to execute the query.
*Execution Engine:The Execution Engine is responsible for executing the optimized execution plan generated by the Query Optimizer. The Execution 
Engine can use various processing frameworks such as MapReduce, Tez, or Spark to process and analyze the data stored in HDFS or other supported 
storage systems.
*User Interface:The User Interface is the interface between the user and the Hive query processor. It allows users to submit queries, monitor query
progress, and retrieve query results.
*Metastore:The Metastore stores metadata about the tables, columns, and partitions that are used in the queries. It is used by the Semantic 
Analyzer and the Execution Engine to validate and execute queries.

Q-6-What are the three different modes in which we can operate Hive?
A-6-*Local Mode:In Local Mode, Hive runs in a single JVM and all the processing happens in the local file system. This mode is useful for small 
data sets and for development and testing purposes.
*MapReduce Mode:In MapReduce Mode, Hive uses Hadoop MapReduce as the processing engine. The data is stored in HDFS and the processing happens in a
distributed manner across the nodes in the Hadoop cluster. This mode is useful for processing large datasets.
*Spark Mode:In Spark Mode, Hive uses Apache Spark as the processing engine. The data is stored in HDFS or other supported storage systems and the 
processing happens in a distributed manner using the Spark engine. This mode is useful for processing large datasets and provides faster processing
speed compared to MapReduce mode.

Q-7-Features and Limitations of Hive.
A-7-
Features of Hive:
*SQL-like Interface: Hive provides a SQL-like interface, called HiveQL, for querying and analyzing data stored in HDFS or other supported storage 
systems. This makes it easy for users who are familiar with SQL to use Hive and perform complex analytics on large datasets.
*Scalability: Hive is highly scalable and can handle large datasets that are distributed across multiple nodes in a Hadoop cluster. It can also be
used in combination with other Hadoop ecosystem tools, such as Pig, HBase, and Sqoop, to build powerful and flexible big data solutions.
*Data Serialization and Deserialization: Hive supports various data serialization and deserialization formats, including Apache Avro, JSON, and 
Parquet, which makes it easy to work with data stored in different formats.
*Extensible: Hive is highly extensible and can be customized to meet the specific needs of different organizations. Users can create their own User
-Defined Functions (UDFs), SerDe plugins, and storage handlers to integrate with their existing data processing workflows.
*Data Warehousing: Hive is a powerful tool for building data warehouses and analytical systems. It provides support for partitioning, bucketing,
and indexing, which makes it easy to optimize queries and improve query performance.

Limitations of Hive:
*Query Latency: Hive is designed for batch processing and is not optimized for low-latency queries. This means that it may not be suitable for 
applications that require real-time query responses.
*Limited Support for Transactions: Hive does not provide full support for transactions and does not support rollbacks or ACID (Atomicity, 
Consistency, Isolation, Durability) transactions. This can be a limitation for applications that require transactional support.
*Limited Real-time Data Processing: Hive is not designed for real-time data processing and does not provide support for streaming data. 
Applications that require real-time data processing may need to use other tools, such as Apache Kafka or Apache Flink.
*Steep Learning Curve: Hive can have a steep learning curve for users who are not familiar with Hadoop and the Hadoop ecosystem. It requires 
knowledge of Hadoop configuration and administration, as well as an understanding of the underlying distributed systems and data processing 
frameworks.
*No Indexing on Nested Data: Hive does not support indexing on nested data structures, which can make queries on complex data types, such as JSON
and XML, slow and inefficient.

Q-8-How to create a Database in HIVE?
A-8-create database hive_db;

Q-9-How to create a table in HIVE?
A-9-
create table department_data
(
dept_id int,
dept_name string,
manager_id int,
salary int)
row format delimited
fields terminated by ',';

Q-10-What do you mean by describe and describe extended and describe formatted with respect to database and table
A-10-
*DESCRIBE:DESCRIBE command is used to view the list of columns in a table or view.it basically return list of columns along with their data types
and any comments associated with them.
*DESCRIBE EXTENDED: This command is used to view the extended schema of a database or table. It includes additional information such as column
statistics, location, and file format. 
*DESCRIBE FORMATTED: This command is used to view the detailed schema of a database or table, including information such as column statistics,
partition information, and storage properties.

Q-11-How to skip header rows from a table in Hive?
A-11-set hive.cli.print.header = true;

Q-12-What is a hive operator? What are the different types of hive operators?
A-12-Hive operators are special symbols or words that perform operations on one or more values. Hive supports a wide range of operators, including
arithmetic, comparison, logical, and bitwise operators.
common operators in hive:
*Arithmetic operators: Hive supports all standard arithmetic operators such as +, -, *, /, and %.
*Comparison operators: Hive supports all standard comparison operators such as =, !=, <, >, <=, and >=.
*Logical operators: Hive supports three logical operators: AND, OR, and NOT.
*Bitwise operators: Hive supports three bitwise operators: & (AND), | (OR), and ^ (XOR).
*Relational operators: Hive supports relational operators such as SELECT, FROM, WHERE, GROUP BY, and ORDER BY.
*Join operators: Hive supports join operators such as INNER JOIN, LEFT OUTER JOIN, RIGHT OUTER JOIN, and FULL OUTER JOIN.
*Set operators: Hive supports set operators such as UNION, UNION ALL, INTERSECT, and EXCEPT.
*Conditional operators: Hive supports conditional operators such as CASE, WHEN, and THEN.
*Miscellaneous operators: Hive supports miscellaneous operators such as LIMIT, DISTINCT, and SORT BY.

Q-13-Explain about the Hive Built-In Functions
A-13-some categories of Hive built-in functions:
*Mathematical functions: Hive provides a variety of mathematical functions, including ABS, CEIL, FLOOR, ROUND, EXP, LOG, POWER, and SQRT. These 
functions can be used to perform various mathematical calculations on numeric data.
*String functions: Hive provides a variety of string functions, including CONCAT, SUBSTR, LENGTH, LOWER, UPPER, TRIM, and REPLACE. These functions
can be used to manipulate and extract information from string data.
*Date and time functions: Hive provides a variety of date and time functions, including CURRENT_DATE, CURRENT_TIMESTAMP, YEAR, MONTH, DAY, HOUR, 
MINUTE, SECOND, DATEDIFF, and TIMESTAMPDIFF. These functions can be used to manipulate and extract information from date and time data.
*Conditional functions: Hive provides a variety of conditional functions, including CASE, IF, and COALESCE. These functions can be used to perform
conditional logic in Hive queries.
*Aggregate functions: Hive provides a variety of aggregate functions, including AVG, SUM, MIN, MAX, COUNT, and GROUP_CONCAT. These functions can be
used to calculate summary statistics on data in Hive.
Array functions: Hive provides a variety of array functions, including ARRAY, SIZE, SORT_ARRAY, CONCAT_WS, and EXPLODE. These functions can be used
to manipulate and extract information from array data.

Q-14-Write hive DDL and DML commands.
A-14-Data Definition Language (DDL) commands:create database hive_db; drop database hive_db; create table department_data(dept_id int,dept_name 
string,manager_id int,salary int)row format delimited fields terminated by ','; 
Data Manipulation Language (DML) commands:select * from department_data; 

Q-15-Explain about SORT BY, ORDER BY, DISTRIBUTE BY and CLUSTER BY in Hive.
A-15-*SORT BY: The SORT BY clause is used to sort data within a reducer.It does not guarantee the order of output records across multiple reducers
Syntax: SELECT * FROM table_name SORT BY column_name;
*ORDER BY: The ORDER BY clause is used to sort data across all reducers.It guarantees the order of output records across multiple reducers.
Syntax: SELECT * FROM table_name ORDER BY column_name;
*DISTRIBUTE BY: The DISTRIBUTE BY clause is used to determine the partitioning of the data in a table. It ensures that the data is divided among
reducers based on the specified column(s).
Syntax: SELECT * FROM table_name DISTRIBUTE BY column_name;
*CLUSTER BY: The CLUSTER BY clause is used to sort data within a reducer and to determine the bucketing of the data in a table. It ensures
that the data is divided among reducers based on the specified column(s) and sorted within each reducer.
Syntax: SELECT * FROM table_name CLUSTER BY column_name;

Q-16-Difference between "Internal Table" and "External Table" and Mention when to choose “Internal Table” and “External Table” in Hive?
A-16-Internal Tables: Internal tables are stored in a directory managed by Hive. When you drop an internal table, both the metadata and the data 
are deleted. The data is managed by Hive and is stored in a location that is managed by Hive.
External Tables: External tables are similar to internal tables, except that the data is stored outside of Hive. When you drop an external table, 
only the metadata is deleted, and the data remains intact. The data is managed by the user and is stored in a location that is not managed by Hive.

*internal tables are useful for managing data within the Hive ecosystem. They are easier to manage, as the data and metadata are managed by Hive, 
and they are more performant, as they are optimized for use within Hive while External tables are suitable when the data needs to be shared between
multiple systems,or when the data needs to be accessed outside of Hive. This means that external tables are useful for managing data that needs to
be accessed by multiple applications.

Q-17-Where does the data of a Hive table get stored?
A-17-The data of internal table stored into warehouse directory of HDFS managed by hive and the data of external table is already present in HDFS
file location not managed by hive and we make table top on it and we can specify location for both tables at the time of creation.

Q-18-Is it possible to change the default location of a managed table?
A-18-Yes, it is possible to change the default location of a managed table in Hive.The default location for managed tables in Hive is in the 
directoryspecified by the hive.metastore.warehouse.dir configuration property.
CREATE TABLE my_table (id INT,name STRING)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
STORED AS TEXTFILE
LOCATION '/my/custom/path/my_table';

Q-19-What is a metastore in Hive? What is the default database provided by Apache Hive for metastore?
A-19-the metastore is a central repository that stores metadata about Hive tables, including their schema, data types, partitioning information,
and location of the data. The metastore is used by Hive to manage tables and to perform operations such as creating, dropping, and altering tables.
The default database provided by Apache Hive for the metastore is Derby. Derby is an embedded Java database that is included with Hive, and it is
suitable for small deployments or testing environments.

Q-20-Why does Hive not store metadata information in HDFS?
A-20-Hive does not store metadata information in HDFS because HDFS is designed for storing large data files and is optimized for sequential 
read/write operations. Storing metadata in HDFS would require accessing and updating small files frequently, which can be inefficient and slow down
Hive operations.Instead, Hive stores metadata information in a separate component called the metastore. The metastore stores metadata in a database
that can be accessed by all nodes in the Hive cluster. This allows Hive to efficiently manage metadata and perform operations such as creating,
dropping, and altering tables without affecting the performance of HDFS.

Q-21-What is a partition in Hive? And Why do we perform partitioning in Hive?
A-21-partitioning is a way to divide a large table into smaller, more manageable parts based on the values of one or more columns. Each partition
is stored as a separate directory on the filesystem, and contains a subset of the data in the table.
Partitioning can be performed on one or more columns, and the columns used for partitioning are called partition keys.partitioning in Hive is a 
powerful technique for managing large datasets, improving query performance, and making data more manageable and available.

Q-22-What is the difference between dynamic partitioning and static partitioning?
A-22-In static partitioning, the partitions are created and managed explicitly by the user. When creating a table with static partitioning, you 
must specify the partition keys and the values for each partition.Static partitioning is useful when you know the partitioning scheme in advance 
and the data is relatively static.
in dynamic partitioning, partitions are created automatically based on the values of the partition keys in the data. When you insert data into a 
table with dynamic partitioning, Hive determines the partition key values from the data and creates the appropriate partition directories 
automatically. Dynamic partitioning is useful when the partitioning scheme is not known in advance or the data is highly dynamic.

Q-23-How do you check if a particular partition exists?
A-23-DESCRIBE sales PARTITION (year=2022, month=1);
If the partition exists, Hive will display the schema and location information for that partition. If the partition does not exist, Hive will 
return an empty result set.

Q-24-How can you stop a partition form being queried?
A-24-

Q-25-Why do we need buckets? How Hive distributes the rows into buckets?
A-25-

Q-26-In Hive, how can you enable buckets?
A-26-

Q-27-How does bucketing help in the faster execution of queries?
A-27-

Q-28-How to optimise Hive Performance? Explain in very detail.
A-28-

Q-29-What is the use of Hcatalog?
A-29-

Q-30- Explain about the different types of join in Hive.
A-30-

Q-31-Is it possible to create a Cartesian join between 2 tables, using Hive?
A-31-

Q-32-Explain the SMB Join in Hive?
A-32-

Q-33-What is the difference between order by and sort by which one we should use?
A-33-

Q-34-What is the usefulness of the DISTRIBUTED BY clause in Hive?
A-34-

Q-35-How does data transfer happen from HDFS to Hive?
A-35-

Q-36-Wherever (Different Directory) I run the hive query, it creates a new metastore_db, please explain the reason for it?
A-36-

Q-37-What will happen in case you have not issued the command: ‘SET hive.enforce.bucketing=true;’ before bucketing a table in Hive?
A-37-

Q-38-Can a table be renamed in Hive?
A-38-

Q-39-Write a query to insert a new column(new_col INT) into a hive table at a position before an existing column (x_col)
A-39-

Q-40-What is serde operation in HIVE?
A-40-

Q-41-Explain how Hive Deserializes and serialises the data?
A-41

Q-42-Write the name of the built-in serde in hive.
A-42-

Q-43-What is the need of custom Serde?
A-43-

Q-44-Can you write the name of a complex data type(collection data types) in
Hive?
A-44-

Q-45-Can hive queries be executed from script files? How?
A-45-

Q-46-What are the default record and field delimiter used for hive text files?
A-46-

Q-47-How do you list all databases in Hive whose name starts with s?
A-47-

Q-48-.What is the difference between LIKE and RLIKE operators in Hive?
A-48-

Q-49-How to change the column data type in Hive?
A-49-

Q-50-How will you convert the string ’51.2’ to a float value in the particular column?
A-50-

Q-51-What will be the result when you cast ‘abc’ (string) as INT?
A-51-

Q-52-What does the following query do?
a. INSERT OVERWRITE TABLE employees
b. PARTITION (country, state)
c. SELECT ..., se.cnty, se.st
d. FROM staged_employees se;
A-52-

Q-53-Write a query where you can overwrite data in a new table from the existing table.
A-53-

Q-54-What is the maximum size of a string data type supported by Hive? Explain how Hive supports binary formats.
A-54-

Q-55-What File Formats and Applications Does Hive Support?
A-55-

Q-56-How do ORC format tables help Hive to enhance its performance?
A-56-

Q-57-How can Hive avoid mapreduce while processing the query?
A-57-

Q-58-What is view and indexing in hive?
A-58-

Q-59-Can the name of a view be the same as the name of a hive table?
A-59-

Q-60-What types of costs are associated in creating indexes on hive tables?
A-60-

Q-61-Give the command to see the indexes on a table.
A-61-

Q-62-Explain the process to access subdirectories recursively in Hive queries.
A-62-

Q-63-If you run a select * query in Hive, why doesn't it run MapReduce?
A-63-

Q-64-What are the uses of Hive Explode?
A-64-

Q-65- What is the available mechanism for connecting applications when we run Hive as a server?
A-65-

Q-66-Can the default location of a managed table be changed in Hive?
A-66-

Q-67-What is the Hive ObjectInspector function?
A-67-

Q-68-What is UDF in Hive?
A-68-

Q-69-Write a query to extract data from hdfs to hive.
A-69-

Q-70-What is TextInputFormat and SequenceFileInputFormat in hive.
A-70-

Q-71-How can you prevent a large job from running for a long time in a hive?
A-71-

Q-72-When do we use explode in Hive?
A-72-

Q-73-Can Hive process any type of data formats? Why? Explain in very detail
A-73-

Q-74-Whenever we run a Hive query, a new metastore_db is created. Why?
A-74-

Q-75-Can we change the data type of a column in a hive table? Write a complete query.
A-75-

Q-76-While loading data into a hive table using the LOAD DATA clause, how do you specify it is a hdfs file and not a local file ?
A-76-

Q-77-What is the precedence order in Hive configuration?
A-77-

Q-78-Which interface is used for accessing the Hive metastore?
A-78-

Q-79-Is it possible to compress json in the Hive external table ?
A-79-

Q-80-What is the difference between local and remote metastores?
A-80-

Q-81-What is the purpose of archiving tables in Hive?
A-81-

Q-82-What is DBPROPERTY in Hive?
A-82-

Q-83-Differentiate between local mode and MapReduce mode in Hive.
A-83-















